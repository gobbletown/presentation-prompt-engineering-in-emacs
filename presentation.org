#+MACRO: NEWLINE @@latex:\\@@ @@html:<br>@@ @@ascii:|@@

#+BEGIN_COMMENT
https://oeis.org/wiki/List_of_LaTeX_mathematical_symbols

Relation symbols
http://garsia.math.yorku.ca/MPWP/LATEXmath/node8.html


https://tex.stackexchange.com/questions/327844/real-number-symbol-r-not-working/327847
\newcommand{\R}{\mathbb{R}}

@@latex:\includegraphics{/home/shane/dump/home/shane/notes/uni/cosc/420_Neural Networks_S1/research/case-for-learned-index-structures/frontpage.png}@@
#+END_COMMENT

#+TITLE:     Presenting... {{{NEWLINE}}} /*Prompt Engineering in Emacs*/ {{{NEWLINE}}}
#+AUTHOR:    Shane Mulligan {{{NEWLINE}}}
#+EMAIL:     mullikine@gmail.com
#+DATE:      <2021-03-01 Mon>
#+DESCRIPTION:
#+KEYWORDS:
#+LANGUAGE:  en
# #+OPTIONS:   H:3 num:t toc:t \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   H:3 num:t toc:nil \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+INFOJS_OPT: view:nil toc:nil ltoc:t mouse:underline buttons:0 path:https://orgmode.org/org-info.js
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+LINK_UP:
#+LINK_HOME:

#+HTML_DOCTYPE: <!DOCTYPE html>
#+HTML_HEAD: <link href="http://fonts.googleapis.com/css?family=Roboto+Slab:400,700|Inconsolata:400,700" rel="stylesheet" type="text/css" />
#+HTML_HEAD: <link href="css/style.css" rel="stylesheet" type="text/css" />

# #+INCLUDE: "beamer-config.org"

#+BEAMER_THEME: Rochester [height=20pt]

#+ATTR_LATEX: :center nil

* Presentation
*** Following along
**** Repositories for following along
#+latex: {\footnotesize
| github1s.com/mullikine/presentation-prompt-engineering-in-emacs         |
| github1s.com/semiosis/examplary                                         |
| github1s.com/semiosis/pen.el                                            |
| github1s.com/semiosis/prompts                                           |
| github1s.com/semiosis/prompt-engineering-patterns                       |
| github1s.com/minimaxir/gpt-3-client                                     |
|  |
#+latex: }

**** Demo
#+latex: {\footnotesize
#+BEGIN_SRC bash -n :i bash :async :results verbatim code
  ssh -oBatchMode=no shane@124.197.60.232 -p 9922
#+END_SRC
#+latex: }

* Preliminaries
** GPT-3
*** Text Generator
**** Background knowledge
#+latex: {\footnotesize
- =GPT-3= is a =seq2seq= model (a text generator)
  - It's stochastic but can be configured to be deterministic.
#+latex: }

**** Key concepts
#+latex: {\footnotesize
- prompt,
- completion, and
- tokens
#+latex: }

**** Limitations
#+latex: {\footnotesize
Combined, the text prompt and generated
completion must be below 2048 tokens (roughly
~1500 words).

+ context-stuffing :: With only 2048 tokens, you need to make
      use of your real estate by providing
      instructions and making implicit
      information explicit.
#+latex: }

** A new programming paradigm
*** Prompt Engineering
**** Characteristics
#+latex: {\footnotesize
- declarative, like =html=
- stochastic, like =problog=
- Unlocks new types of applications
- Speeds up development
#+latex: }

*** Some prompts I've made
**** =generate-vim-command.prompt=
#+latex: {\footnotesize
#+BEGIN_SRC text -n :async :results verbatim code
  Vim

  Insert "Q: " at the start of the line
  :%s/^/Q: /g.
  ###
  Remove whitespace from the start of each line
  :%s/^\s*/\1/g
  ###
  Join each line with the next line
  :1,$j
  ###
  Make all occurrences of Steve lowercase
  :%s/Steve/steve/g
  ###
  <1>
#+END_SRC
#+latex: }

*** Tasks suitable for GPT-3
**** Classification
- Tweet Sentiment
- Company categorization
- Labeling parts of speech

#+latex: {\footnotesize
- http://github.com/semiosis/prompts/blob/master/prompts/tweet-sentiment-classifier.prompt
- http://github.com/semiosis/prompts/blob/master/prompts/keyword-extraction.prompt
#+latex: }

**** Generation
- Tweet Sentiment
- Company categorization
- Labeling parts of speech

*** Design patterns
**** =generate-vim-command.prompt=
#+latex: {\footnotesize
#+BEGIN_SRC text -n :async :results verbatim code
  Vim

  Insert "Q: " at the start of the line
  :%s/^/Q: /g.
  ###
  Remove whitespace from the start of each line
  :%s/^\s*/\1/g
  ###
  Join each line with the next line
  :1,$j
  ###
  Make all occurrences of Steve lowercase
  :%s/Steve/steve/g
  ###
  <1>
#+END_SRC
#+latex: }

* Explanations
** Using =pen.el=
*** Prompt YAML format Part 1
**** =meeting-bullets-to-summary.prompt=
#+BEGIN_SRC yaml -n :async :results verbatim code
  title: "meeting bullet points to summary"
  prompt: |+
      Convert my short hand into a first-hand
      account of the meeting:
  
      <1>
  
      Summary:
  engine: "davinci-instruct-beta"
  temperature: 0.7
  max-tokens: 60
#+END_SRC

*** Prompt YAML format Part 2
**** =meeting-bullets-to-summary.prompt=
#+BEGIN_SRC yaml -n :async :results verbatim code
  top-p: 1
  frequency-penalty: 0.0
  presence-penalty: 0.0
  best-of: 1
  stop-sequences:
  - "\n\n"
  conversation-mode: no
  stitch-max: 0
#+END_SRC

+ stitch-max :: Keep stitching together until reaching this limit.
                This allows a full response for answers which may need n*max-tokens to reach the stop-sequence.

*** Prompt YAML format: Part 3
**** =meeting-bullets-to-summary.prompt=
#+BEGIN_SRC yaml -n :async :results verbatim code
  vars:
  - "notes"
  examples:
  - |+
      Tom: Profits up 50%
      Jane: New servers are online
      Kjel: Need more time to fix software
      Jane: Happy to help
      Parkman: Beta testing almost done
#+END_SRC

* =semiosis=
** =pen.el=
*** =Prompts as functions=
**** =pen-generate-prompt-functions=
Generate prompt functions for the files in the
prompts directory Function names are prefixed
with =pen-pf-= for easy searching.

http://github.com/semiosis/prompts

** =examplary=
*** =examplary=: examples as functions
An example-oriented DSL that can be used to
construct and compose NLP tasks.

Why is a DSL needed for this? Just to make the
code a little more terse.

**** Regex
https://github.com/pemistahl/grex

#+latex: {\footnotesize
#+BEGIN_SRC clojure -n :i clj :async :results verbatim code
  (def regex
    "example 1\nexample2" "^example [12]$"
    "example 2\nexample3" "^example [23]$"
    "pi4\npi5" "^pi[45]$")
#+END_SRC
#+latex: }

*** =examplary=: examples as functions
**** Analogy
#+latex: {\footnotesize
#+BEGIN_SRC clojure -n :i clj :async :results verbatim code
  (def analogy
    ;; Each line is a training example.
    "NNs" "NNs are like genetic algorithms in
    that both are systems that learn from
    experience"
    "Social media" "Social media is like a
    market in that both are systems that
    coordinate the actions of many
    individuals.")

  (def field
    "chemistry" "study of chemicals"
    "biology" "study of living things")
#+END_SRC
#+latex: }

* Demonstrations
*** Something funny
**** Vexate a simple instruction
[[./complicate.png]]

*** Create a prompt
**** Ask the audience
- What type of text to generate
  - Could be code, prose, etc.

* Appendix
** Additional reading
*** Tutorials
**** Ruby
#+latex: {\footnotesize
https://www.twilio.com/blog/generating-cooking-recipes-openai-gpt3-ruby
#+latex: }