% Created 2021-03-02 Tue 14:44
% Intended LaTeX compiler: pdflatex
\documentclass[presentation]{beamer}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usetheme[height=20pt]{Rochester}
\author{Shane Mulligan \\  }
\date{\textit{<2021-03-01 Mon>}}
\title{Presenting\ldots{} \\   \emph{\alert{Prompt Engineering in Emacs}} \\  }
\hypersetup{
 pdfauthor={Shane Mulligan \\  },
 pdftitle={Presenting\ldots{} \\   \emph{\alert{Prompt Engineering in Emacs}} \\  },
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 27.0.91 (Org mode 9.3)}, 
 pdflang={English}}
\begin{document}

\maketitle

\section{Presentation}
\label{sec:orgd4df98e}
\begin{frame}[label={sec:org6cfc67a},fragile]{Following along}
 \begin{block}{Repositories for following along}
{\footnotesize
\begin{center}
\begin{tabular}{l}
github1s.com/mullikine/presentation-prompt-engineering-in-emacs\\
github1s.com/semiosis/examplary\\
github1s.com/semiosis/pen.el\\
github1s.com/semiosis/prompts\\
github1s.com/semiosis/prompt-engineering-patterns\\
github1s.com/minimaxir/gpt-3-client\\
\\
\end{tabular}
\end{center}
}
\end{block}

\begin{block}{Demo}
{\footnotesize
\begin{verbatim}
1  ssh -oBatchMode=no shane@124.197.60.232 -p 9922
\end{verbatim}
}
\end{block}
\end{frame}

\section{Preliminaries}
\label{sec:org0235586}
\subsection{GPT-3}
\label{sec:orgb5d02ca}
\begin{frame}[label={sec:orgb8c8a6e},fragile]{Text Generator}
 \begin{block}{Background knowledge}
{\footnotesize
\begin{itemize}
\item \texttt{GPT-3} is a \texttt{seq2seq} model (a text generator)
\begin{itemize}
\item It's stochastic but can be configured to be deterministic.
\end{itemize}
\end{itemize}
}
\end{block}

\begin{block}{Key concepts}
{\footnotesize
\begin{itemize}
\item prompt,
\item completion, and
\item tokens
\end{itemize}
}
\end{block}

\begin{block}{Limitations}
{\footnotesize
Combined, the text prompt and generated
completion must be below 2048 tokens (roughly
\textasciitilde{}1500 words).

\begin{description}
\item[{context-stuffing}] With only 2048 tokens, you need to make
use of your real estate by providing
instructions and making implicit
information explicit.
\end{description}
}
\end{block}
\end{frame}

\subsection{A new programming paradigm}
\label{sec:org6de1406}
\begin{frame}[label={sec:org6fb75ed},fragile]{Prompt Engineering}
 \begin{block}{Characteristics}
{\footnotesize
\begin{itemize}
\item declarative, like \texttt{html}
\item stochastic, like \texttt{problog}
\item Unlocks new types of applications
\item Speeds up development
\end{itemize}
}
\end{block}
\end{frame}

\begin{frame}[label={sec:org552f7d2},fragile]{Some prompts I've made}
 \begin{block}{\texttt{generate-vim-command.prompt}}
{\footnotesize
\begin{verbatim}
 1  Vim
 2  
 3  Insert "Q: " at the start of the line
 4  :%s/^/Q: /g.
 5  ###
 6  Remove whitespace from the start of each line
 7  :%s/^\s*/\1/g
 8  ###
 9  Join each line with the next line
10  :1,$j
11  ###
12  Make all occurrences of Steve lowercase
13  :%s/Steve/steve/g
14  ###
15  <1>
\end{verbatim}
}
\end{block}
\end{frame}

\begin{frame}[label={sec:orge7beb45}]{Tasks suitable for GPT-3}
\begin{block}{Classification}
\begin{itemize}
\item Tweet Sentiment
\item Company categorization
\item Labeling parts of speech
\end{itemize}

{\footnotesize
\begin{itemize}
\item \url{http://github.com/semiosis/prompts/blob/master/prompts/tweet-sentiment-classifier.prompt}
\item \url{http://github.com/semiosis/prompts/blob/master/prompts/keyword-extraction.prompt}
\end{itemize}
}
\end{block}
\end{frame}

\begin{frame}[label={sec:orgfb6af63}]{Tasks suitable for GPT-3}
\begin{block}{Generation}
\begin{itemize}
\item Idea Generator
\end{itemize}

Come up with silly inventions.

\begin{center}
\includegraphics[width=.9\linewidth]{./silly-inventions.png}
\end{center}
\end{block}
\end{frame}

\begin{frame}[label={sec:org392ec68}]{Tasks suitable for GPT-3}
\begin{block}{Conversation}
\begin{itemize}
\item Q\&A agent
\item Sarcastic chatbot
\end{itemize}

{\footnotesize
\url{http://github.com/semiosis/prompts/blob/master/prompts/sarcastic-response.prompt}
}
\end{block}
\end{frame}

\begin{frame}[label={sec:orgb3c0c56},fragile]{Design patterns}
 Taken from Prompt Design 101.

These are manual techniques which should be
encoded in a DSL when generating prompts.

\begin{block}{Reflective description of the task}
State what the prompt does at the start At the
start of the example we state in plain
language what the classifier does:

\uline{This is a tweet sentiment classifier.}

By stating this up front

it helps the API understand much more quickly
what the goal of the response is supposed to
be

and you‚Äôll end needing to provide fewer
examples.
\end{block}

\begin{block}{Use separators between examples}
Example: \texttt{\#\#\#}.

You can use other characters or line breaks,
but ‚Äú\#\#\#‚Äù works pretty consistently and is
also an easy to use stop sequence.

Whatever separator you use, make sure that
it‚Äôs clear to the API where an example starts
and stops.
\end{block}
\end{frame}

\begin{frame}[label={sec:org485e84b},fragile]{Improving the classifier‚Äôs efficiency}
 Now that we have a grasp of how to build a
classifier, let's take that example and make
it even more efficient so that we can use it
to get multiple results back from one API
call.

\begin{verbatim}
 1  This is a tweet sentiment classifier
 2  Tweet: "I loved the new Batman movie!"
 3  Sentiment: Positive
 4  ###
 5  Tweet: "I hate it when my phone battery dies"
 6  Sentiment: Negative
 7  ###
 8  Tweet: "My day has been üëç"
 9  Sentiment: Positive
10  ###
11  Tweet: "This is the link to the article"
12  Sentiment: Neutral
13  ###
14  Tweet text
15  
16  1. "I loved the new Batman movie!"
17  2. "I hate it when my phone battery dies"
18  3. "My day has been üëç"
19  4. "This is the link to the article"
20  5. "This new music video blew my mind"
21  
22  Tweet sentiment ratings:
23  1: Positive
24  2: Negative
25  3: Positive
26  4: Neutral
27  5: Positive
28  
29  ###
30  Tweet text
31  
32  "I can't stand homework"
33  "This sucks. I'm bored üò†"
34  "I can't wait for Halloween!!!"
35  "My cat is adorable ‚ù§Ô∏è‚ù§Ô∏è"
36  "I hate chocolate"
37  Tweet sentiment ratings:
38  1.
\end{verbatim}

After showing the API how tweets are
classified by sentiment we then provide it a
list of tweets and then a list of sentiment
ratings with the same number index. The API is
able to pick up from the first example how a
tweet is supposed to be classified. In the
second example it sees how to apply this to a
list of tweets. This allows the API to rate
five (and even more) tweets in just one API
call.

It‚Äôs important to note that when you ask the
API to create lists or evaluate text you need
to pay extra attention to your probability
settings (Top P or Temperature) to avoid
drift.

Make sure your probability setting is
calibrated correctly by running multiple
tests.

Don‚Äôt make your list too long or the API is
likely to drift.
\end{frame}

\begin{frame}[label={sec:orgdb53aa7}]{Techniques}
\begin{block}{Query Reformulation}
\url{https://www.sciencedirect.com/topics/computer-science/query-reformulation}

You can improve the quality of the responses
by making a longer more diverse list in your
prompt.

One way to do that is to start off with one
example, let the API generate more and select
the ones that you like best and add them to
the list.

A few more high-quality variations can
dramatically improve the quality of the
responses.
\end{block}
\end{frame}

\section{Explanations}
\label{sec:org6d9553e}
\subsection{Using \texttt{pen.el}}
\label{sec:orgb2738b3}
\begin{frame}[label={sec:org9814788},fragile]{Prompt YAML format Part 1}
 \begin{block}{\texttt{meeting-bullets-to-summary.prompt}}
\begin{verbatim}
 1  title: "meeting bullet points to summary"
 2  prompt: |+
 3      Convert my short hand into a first-hand
 4      account of the meeting:
 5  
 6      <1>
 7  
 8      Summary:
 9  engine: "davinci-instruct-beta"
10  temperature: 0.7
11  max-tokens: 60
\end{verbatim}
\end{block}
\end{frame}

\begin{frame}[label={sec:org6aa24a5},fragile]{Prompt YAML format Part 2}
 \begin{block}{\texttt{meeting-bullets-to-summary.prompt}}
\begin{verbatim}
1  top-p: 1
2  frequency-penalty: 0.0
3  presence-penalty: 0.0
4  best-of: 1
5  stop-sequences:
6  - "\n\n"
7  conversation-mode: no
8  stitch-max: 0
\end{verbatim}

\begin{description}
\item[{stitch-max}] Keep stitching together until reaching this limit.
This allows a full response for answers which may need n*max-tokens to reach the stop-sequence.
\end{description}
\end{block}
\end{frame}

\begin{frame}[label={sec:org965041a},fragile]{Prompt YAML format: Part 3}
 \begin{block}{\texttt{meeting-bullets-to-summary.prompt}}
\begin{verbatim}
1  vars:
2  - "notes"
3  examples:
4  - |+
5      Tom: Profits up 50%
6      Jane: New servers are online
7      Kjel: Need more time to fix software
8      Jane: Happy to help
9      Parkman: Beta testing almost done
\end{verbatim}
\end{block}
\end{frame}

\section{\texttt{semiosis}}
\label{sec:org12295b8}
\subsection{\texttt{pen.el}}
\label{sec:org5b2a1a8}
\begin{frame}[label={sec:org066ae20},fragile]{\texttt{Prompts as functions}}
 \begin{block}{\texttt{pen-generate-prompt-functions}}
Generate prompt functions for the files in the
prompts directory Function names are prefixed
with \texttt{pen-pf-} for easy searching.

\url{http://github.com/semiosis/prompts}
\end{block}
\end{frame}

\subsection{\texttt{examplary}}
\label{sec:org030f94b}
\begin{frame}[label={sec:org6b8f57e},fragile]{\texttt{examplary}: examples as functions}
 An example-oriented DSL that can be used to
construct and compose NLP tasks.

Why is a DSL needed for this? Just to make the
code a little more terse.

\begin{block}{Regex}
\url{https://github.com/pemistahl/grex}

{\footnotesize
\begin{verbatim}
1  (def regex
2    "example 1\nexample2" "^example [12]$"
3    "example 2\nexample3" "^example [23]$"
4    "pi4\npi5" "^pi[45]$")
\end{verbatim}
}
\end{block}
\end{frame}

\begin{frame}[label={sec:orgb7cc436},fragile]{\texttt{examplary}: examples as functions}
 \begin{block}{Analogy}
{\footnotesize
\begin{verbatim}
 1  (def analogy
 2    ;; Each line is a training example.
 3    "NNs" "NNs are like genetic algorithms in
 4    that both are systems that learn from
 5    experience"
 6    "Social media" "Social media is like a
 7    market in that both are systems that
 8    coordinate the actions of many
 9    individuals.")
10  
11  (def field
12    "chemistry" "study of chemicals"
13    "biology" "study of living things")
\end{verbatim}
}
\end{block}
\end{frame}

\section{Demonstrations}
\label{sec:org2d633b9}
\begin{frame}[label={sec:org226d11f}]{Something funny}
\begin{block}{Vexate a simple instruction}
\begin{center}
\includegraphics[width=.9\linewidth]{./complicate.png}
\end{center}
\end{block}
\end{frame}

\begin{frame}[label={sec:orgdaf957d}]{Something funny}
\begin{block}{How to crack an egg}
\begin{center}
\includegraphics[width=.9\linewidth]{./crack-an-egg.png}
\end{center}
\end{block}
\end{frame}

\begin{frame}[label={sec:org3684e51}]{Create a prompt}
\begin{block}{Ask the audience}
\begin{itemize}
\item What type of text to generate
\begin{itemize}
\item Could be code, prose, etc.
\end{itemize}
\end{itemize}
\end{block}
\end{frame}

\section{Appendix}
\label{sec:orgdb9ec53}
\subsection{Additional reading}
\label{sec:org74b38d9}
\begin{frame}[label={sec:org8935915}]{Tutorials}
\begin{block}{Ruby}
{\footnotesize
\url{https://www.twilio.com/blog/generating-cooking-recipes-openai-gpt3-ruby}
}
\end{block}
\end{frame}
\end{document}
