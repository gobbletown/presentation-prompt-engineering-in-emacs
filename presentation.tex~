% Created 2021-03-02 Tue 13:30
% Intended LaTeX compiler: pdflatex
\documentclass[presentation]{beamer}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usetheme[height=20pt]{Rochester}
\author{Shane Mulligan \\  }
\date{\textit{<2021-03-01 Mon>}}
\title{Presenting\ldots{} \\   \emph{\alert{Prompt Engineering in Emacs}} \\  }
\hypersetup{
 pdfauthor={Shane Mulligan \\  },
 pdftitle={Presenting\ldots{} \\   \emph{\alert{Prompt Engineering in Emacs}} \\  },
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 27.0.91 (Org mode 9.3)}, 
 pdflang={English}}
\begin{document}

\maketitle

\section{Presentation}
\label{sec:org49147d4}
\begin{frame}[label={sec:org909d7ac},fragile]{Following along}
 \begin{block}{Repositories for following along}
{\footnotesize
\begin{center}
\begin{tabular}{l}
github1s.com/mullikine/presentation-prompt-engineering-in-emacs\\
github1s.com/semiosis/examplary\\
github1s.com/semiosis/pen.el\\
github1s.com/semiosis/prompts\\
github1s.com/semiosis/prompt-engineering-patterns\\
github1s.com/minimaxir/gpt-3-client\\
\\
\end{tabular}
\end{center}
}
\end{block}

\begin{block}{Demo}
{\footnotesize
\begin{verbatim}
1  ssh -oBatchMode=no shane@124.197.60.232 -p 9922
\end{verbatim}
}
\end{block}
\end{frame}

\section{Preliminaries}
\label{sec:org7742457}
\subsection{GPT-3}
\label{sec:org669f28c}
\begin{frame}[label={sec:org193fd38},fragile]{Text Generator}
 \begin{block}{Background knowledge}
{\footnotesize
\begin{itemize}
\item \texttt{GPT-3} is a \texttt{seq2seq} model (a text generator)
\begin{itemize}
\item It's stochastic but can be configured to be deterministic.
\end{itemize}
\end{itemize}
}
\end{block}

\begin{block}{Key concepts}
{\footnotesize
\begin{itemize}
\item prompt,
\item completion, and
\item tokens
\end{itemize}
}
\end{block}

\begin{block}{Limitations}
{\footnotesize
Combined, the text prompt and generated
completion must be below 2048 tokens (roughly
\textasciitilde{}1500 words).

\begin{description}
\item[{context-stuffing}] With only 2048 tokens, you need to make
use of your real estate by providing
instructions and making implicit
information explicit.
\end{description}
}
\end{block}
\end{frame}

\subsection{A new programming paradigm}
\label{sec:org4bc2403}
\begin{frame}[label={sec:orgb8a3e3d},fragile]{Prompt Engineering}
 \begin{block}{Characteristics}
{\footnotesize
\begin{itemize}
\item declarative, like \texttt{html}
\item stochastic, like \texttt{problog}
\item Unlocks new types of applications
\item Speeds up development
\end{itemize}
}
\end{block}
\end{frame}

\section{\texttt{semiosis}}
\label{sec:org02c3b99}
\subsection{\texttt{pen.el}}
\label{sec:org2ebc9e8}
\begin{frame}[label={sec:org9685b38},fragile]{\texttt{Prompts as functions}}
\end{frame}

\subsection{\texttt{examplary}}
\label{sec:org5299ebb}

\section{Demonstrations}
\label{sec:orgce7175f}
\subsection{Using \texttt{pen.el}}
\label{sec:orgfad4bd0}
\begin{frame}[label={sec:org17ab3e5},fragile]{Prompt YAML format Part 1}
 \begin{block}{\texttt{meeting-bullets-to-summary.prompt}}
\begin{verbatim}
 1  title: "meeting bullet points to summary"
 2  prompt: |+
 3      Convert my short hand into a first-hand
 4      account of the meeting:
 5  
 6      <1>
 7  
 8      Summary:
 9  engine: "davinci-instruct-beta"
10  temperature: 0.7
11  max-tokens: 60
\end{verbatim}
\end{block}
\end{frame}

\begin{frame}[label={sec:orgf93c203},fragile]{Prompt YAML format Part 2}
 \begin{block}{\texttt{meeting-bullets-to-summary.prompt}}
\begin{verbatim}
1  top-p: 1
2  frequency-penalty: 0.0
3  presence-penalty: 0.0
4  best-of: 1
5  stop-sequences:
6  - "\n\n"
7  conversation-mode: no
8  stitch-max: 0
\end{verbatim}

\begin{description}
\item[{stitch-max}] Keep stitching together until reaching this limit.
This allows a full response for answers which may need n*max-tokens to reach the stop-sequence.
\end{description}
\end{block}
\end{frame}

\begin{frame}[label={sec:org200a76a},fragile]{Prompt YAML format: Part 3}
 \begin{block}{\texttt{meeting-bullets-to-summary.prompt}}
\begin{verbatim}
1  vars:
2  - "notes"
3  examples:
4  - |+
5      Tom: Profits up 50%
6      Jane: New servers are online
7      Kjel: Need more time to fix software
8      Jane: Happy to help
9      Parkman: Beta testing almost done
\end{verbatim}
\end{block}
\end{frame}

\begin{frame}[label={sec:orgf0eb5ca},fragile]{Some prompts I've made}
 \begin{block}{\texttt{generate-vim-command.prompt}}
{\footnotesize
\begin{verbatim}
 1  Vim
 2  
 3  Insert "Q: " at the start of the line
 4  :%s/^/Q: /g.
 5  ###
 6  Remove whitespace from the start of each line
 7  :%s/^\s*/\1/g
 8  ###
 9  Join each line with the next line
10  :1,$j
11  ###
12  Make all occurrences of Steve lowercase
13  :%s/Steve/steve/g
14  ###
15  <1>
\end{verbatim}
}
\end{block}
\end{frame}

\begin{frame}[label={sec:org4f7b9f9}]{Create a prompt}
\begin{block}{Ask the audience}
\begin{itemize}
\item What type of text to generate
\begin{itemize}
\item Could be code, prose, etc.
\end{itemize}
\end{itemize}
\end{block}
\end{frame}

\section{Appendix}
\label{sec:org16ba227}
\subsection{Additional reading}
\label{sec:org39e5d79}
\begin{frame}[label={sec:org7e8c789}]{Tutorials}
\begin{block}{Ruby}
{\footnotesize
\url{https://www.twilio.com/blog/generating-cooking-recipes-openai-gpt3-ruby}
}
\end{block}
\end{frame}
\end{document}
